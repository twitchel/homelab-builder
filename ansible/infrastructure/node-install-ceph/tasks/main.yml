- name: ensure /var/data exists
  file:
    path: /var/data
    state: directory

- name: ensure /etc/ceph exists
  file:
    path: /etc/ceph
    state: directory

- name: install microceph
  snap:
    name: microceph

- name: install ceph tools
  apt:
    update_cache: yes
    name: "{{ packages }}"
  vars:
    packages:
      - ceph-common
      - nfs-common
  register: _result
  until: _result.failed == false
  retries: 30 # retry X times
  delay: 5     # pause for X sec b/w each call

- name: Configure Ceph on first host
  run_once: true
  delegate_to: "{{ play_hosts[0] }}"
  block:
    - name: have we already been bootstrapped?
      stat:
        path: /etc/ceph/ceph.conf
      register: _ceph_configured

    - name: bootstrap ceph cluster on first host
      command: "microceph cluster bootstrap"
      when: not _ceph_configured.stat.exists

    - name: update CRUSH rules for single instance cluster
      command: "microceph.ceph osd crush rule rm replicated_rule"
      when: (play_hosts | length) == 1 and (not _ceph_configured.stat.exists)

    - name: update CRUSH rules for single instance cluster
      command: "microceph.ceph osd crush rule create-replicated single default osd"
      when: (play_hosts | length) == 1 and (not _ceph_configured.stat.exists)

    - name: prepare disk SDB for microceph
      command: "microceph disk add /dev/sdb --wipe"
      when: not _ceph_configured.stat.exists

    - name: Create metadata OSD pool
      command: "microceph.ceph osd pool create cephfs_meta"
      when: not _ceph_configured.stat.exists

    - name: Create data OSD pool
      command: "microceph.ceph osd pool create cephfs_data"
      when: not _ceph_configured.stat.exists

    - name: Create ceph filesystem
      command: "microceph.ceph fs new data cephfs_meta cephfs_data"
      when: not _ceph_configured.stat.exists

    - name: Create symlink for ceph.keyring
      command: "ln -s /var/snap/microceph/current/conf/ceph.keyring /etc/ceph/ceph.keyring"
      when: not _ceph_configured.stat.exists

    - name: Create symlink for ceph.conf
      command: "ln -s /var/snap/microceph/current/conf/ceph.conf /etc/ceph/ceph.conf"
      when: not _ceph_configured.stat.exists

- name: Join the cluster from the other nodes
  when: inventory_hostname != play_hosts[0]
  block:
    - name: have we already been bootstrapped?
      stat:
        path: /etc/ceph/ceph.conf
      register: _ceph_configured

    - name: generate join token for {{ inventory_hostname }}
      delegate_to: "{{ play_hosts[0] }}"
      command: "microceph cluster add {{ inventory_hostname }}"
      when: not _ceph_configured.stat.exists
      register: _join_token

    - name: join cluster from {{ inventory_hostname }}
      command: "microceph cluster join {{ _join_token.stdout }}"
      when: not _ceph_configured.stat.exists

    - name: prepare disk SDB for microceph
      command: "microceph disk add /dev/sdb --wipe"
      when: not _ceph_configured.stat.exists

    - name: Create symlink for ceph.keyring
      command: "ln -s /var/snap/microceph/current/conf/ceph.keyring /etc/ceph/ceph.keyring"
      when: not _ceph_configured.stat.exists

    - name: Create symlink for ceph.conf
      command: "ln -s /var/snap/microceph/current/conf/ceph.conf /etc/ceph/ceph.conf"
      when: not _ceph_configured.stat.exists

#
#- name: Configure Ceph on first host
#  run_once: true
#  delegate_to: "{{ play_hosts[0] }}"
#  block:
#
#    - name: have we already been bootstrapped?
#      stat:
#        path: /etc/ceph/ceph.conf
#      register: _ceph_configured
#
#    - name: bootstrap ceph cluster on first host
#      command: "cephadm bootstrap --mon-ip {{ hostvars[play_hosts[0]].ansible_host }}"
#      when: not _ceph_configured.stat.exists
#
#    - name: write dashboard password to disk
#      copy:
#        dest: /tmp/ceph-dashboard-credentials
#        content: "{{ ceph_dashboard_password }}"
#
#    - name: add credentials for dashboard access
#      command: "ceph dashboard ac-user-create {{ ceph_dashboard_username }} administrator -i /tmp/ceph-dashboard-credentials"
#      when: not _ceph_configured.stat.exists
#
#    - name: remove dashboard password from disk
#      file:
#        path: /tmp/ceph-dashboard-credentials
#        state: absent
#
#    - name: get SSH public key from first host
#      command: cat /etc/ceph/ceph.pub
#      register: cephadm_ssh_public_key
#
#    - name: get ceph admin keyring from first host
#      command: cat /etc/ceph/ceph.client.admin.keyring
#      register: ceph_admin_keyring
#
#    - name: get ceph/ceph.conf from first host
#      command: cat /etc/ceph/ceph.conf
#      register: ceph_conf
#
#- name: prepare other hosts to join the cluster
#  when: inventory_hostname != play_hosts[0]
#  block:
#
#    - name: deploy cephadm ssh key on other hosts
#      authorized_key:
#        user: root
#        key: "{{ cephadm_ssh_public_key.stdout }}"
#
#    - name: deploy ceph admin keyring to other hosts
#      copy:
#        dest: /etc/ceph/ceph.client.admin.keyring
#        content: "{{ ceph_admin_keyring.stdout }}\n"
#
#    - name: deploy ceph/ceph.conf to other hosts
#      copy:
#        dest: /etc/ceph/ceph.conf
#        content: "{{ ceph_conf.stdout }}\n"
#
- name: expand the cluster to the other hosts and setup file system
  delegate_to: "{{ play_hosts[0] }}"
  run_once: true
  block:
    - name: do we have an mds up yet? (try for 20 min)
      shell: ceph -s | grep mds
      register: _result
      until: _result.failed == false
      retries: 120 # retry X times
      delay: 10    # pause for X sec b/w each call

    - name: do we have HEALTH_OK yet? (try for 20 min)
      shell: ceph -s | grep HEALTH_OK
      register: _result
      until: _result.failed == false
      retries: 120 # retry X times
      delay: 10    # pause for X sec b/w each call

- name: concatenate the names of all the hosts for the next 2 steps
  set_fact:
    _ceph_mons: "{{ play_hosts | join(',') }}"

- name: add cephfs mount to /etc/fstab, and mount it
  mount:
    src: "{{ _ceph_mons }}:/"
    path: /var/data
    state: mounted
    fstype: ceph
    opts: name=admin,fs=data
  register: _result
  until: _result.failed == false
  retries: 60 # retry X times
  delay: 5     # pause for X sec b/w each call