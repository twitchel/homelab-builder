- name: ensure /var/data exists
  file:
    path: /var/data
    state: directory

- name: ensure /etc/ceph exists
  file:
    path: /etc/ceph
    state: directory

- name: install microceph
  snap:
    name: microceph

- name: install ceph tools
  apt:
    update_cache: yes
    name: "{{ packages }}"
  vars:
    packages:
      - ceph-common
      - nfs-common
  register: _result
  until: _result.failed == false
  retries: 30 # retry X times
  delay: 5     # pause for X sec b/w each call

- name: Configure Ceph on first host
  run_once: true
  delegate_to: "{{ play_hosts[0] }}"
  block:
    - name: have we already been bootstrapped?
      stat:
        path: /etc/ceph/ceph.conf
      register: _ceph_configured

    - name: bootstrap ceph cluster on first host
      command: "microceph cluster bootstrap"
      when: not _ceph_configured.stat.exists

    - name: update CRUSH rules for single instance cluster
      command: "microceph.ceph osd crush rule rm replicated_rule"
      when: (play_hosts | length) == 1 and (not _ceph_configured.stat.exists)

    - name: update CRUSH rules for single instance cluster
      command: "microceph.ceph osd crush rule create-replicated single default osd"
      when: (play_hosts | length) == 1 and (not _ceph_configured.stat.exists)

    - name: prepare disk SDB for microceph
      command: "microceph disk add /dev/sdb --wipe"
      when: not _ceph_configured.stat.exists

    - name: Create metadata OSD pool
      command: "microceph.ceph osd pool create cephfs_meta"
      when: not _ceph_configured.stat.exists

    - name: Create data OSD pool
      command: "microceph.ceph osd pool create cephfs_data"
      when: not _ceph_configured.stat.exists

    - name: Create ceph filesystem
      command: "microceph.ceph fs new data cephfs_meta cephfs_data"
      when: not _ceph_configured.stat.exists

    - name: Create symlink for ceph.keyring
      command: "ln -s /var/snap/microceph/current/conf/ceph.keyring /etc/ceph/ceph.keyring"
      when: not _ceph_configured.stat.exists

    - name: Create symlink for ceph.conf
      command: "ln -s /var/snap/microceph/current/conf/ceph.conf /etc/ceph/ceph.conf"
      when: not _ceph_configured.stat.exists

- name: Join the cluster from the other nodes
  when: inventory_hostname != play_hosts[0]
  block:
    - name: have we already been bootstrapped?
      stat:
        path: /etc/ceph/ceph.conf
      register: _ceph_configured

    - name: generate join token for {{ inventory_hostname }}
      delegate_to: "{{ play_hosts[0] }}"
      command: "microceph cluster add {{ inventory_hostname }}"
      when: not _ceph_configured.stat.exists
      register: _join_token

    - name: join cluster from {{ inventory_hostname }}
      command: "microceph cluster join {{ _join_token.stdout }}"
      when: not _ceph_configured.stat.exists

    - name: prepare disk SDB for microceph
      command: "microceph disk add /dev/sdb --wipe"
      when: not _ceph_configured.stat.exists

    - name: Create symlink for ceph.keyring
      command: "ln -s /var/snap/microceph/current/conf/ceph.keyring /etc/ceph/ceph.keyring"
      when: not _ceph_configured.stat.exists

    - name: Create symlink for ceph.conf
      command: "ln -s /var/snap/microceph/current/conf/ceph.conf /etc/ceph/ceph.conf"
      when: not _ceph_configured.stat.exists

- name: expand the cluster to the other hosts and setup file system
  delegate_to: "{{ play_hosts[0] }}"
  run_once: true
  block:
    - name: do we have an mds up yet? (try for 20 min)
      shell: ceph -s | grep mds
      register: _result
      until: _result.failed == false
      retries: 120 # retry X times
      delay: 10    # pause for X sec b/w each call

    - name: do we have HEALTH_OK yet? (try for 20 min)
      shell: ceph -s | grep HEALTH_OK
      register: _result
      until: _result.failed == false
      retries: 120 # retry X times
      delay: 10    # pause for X sec b/w each call

- name: concatenate the names of all the hosts for the next 2 steps
  set_fact:
    _ceph_mons: "{{ play_hosts | join(',') }}"

- name: add cephfs mount to /etc/fstab, and mount it
  mount:
    src: "{{ _ceph_mons }}:/"
    path: /var/data
    state: mounted
    fstype: ceph
    opts: name=admin,fs=data
  register: _result
  until: _result.failed == false
  retries: 60 # retry X times
  delay: 5     # pause for X sec b/w each call